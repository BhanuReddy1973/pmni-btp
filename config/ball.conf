general {
    dataset_class = models.dataset_loader.Dataset
    renderer_class = models.renderer.NeuSRenderer

    base_exp_dir = ./exp/special_normals/CASE_NAME
    recording = [
        ./,
        ./models
    ]
    pose_init_radius = 1.5
    pose_init_angle = 0
    clock_wise = False 
}

dataset {
    data_dir = ./data/special_normals/CASE_NAME
    normal_dir = normal_camera_space_sdmunips #normal_camera_space_sdmunips # choose camera normal maps
    cameras_name = cameras_sphere.npz
    exclude_views = []  # index of views to exclude for test purpose, 0-based
    upsample_factor = 1
    depth_dir = integration/depth
    perspective_dir = integration/perspective
    add_pose_noise = False
    rotation_noise_std=0.1
    translation_noise_std=0.5
    depth_init_scale = 1.5
}

train {

    change_posenet_epoch = 2000
    add_normal_loss_epoch = 4000
    #learing rate group
    learning_rate = 5e-4
    learning_rate_alpha = 0.05
    pose_lr = 5e-4
    scale_lr =5e-4
    end_iter = 30000
    increase_bindwidth_every = 1000
    warm_up_end = 500
    gradient_method = ad  
    batch_size = 4096
    patch_size = 1  # i.e., each training step samples 2048 patches of 3x3 pixels
    use_white_bkgd = False
    pc_ratio = 2

    #loss type
    loss_type = l2  # for normal loss
    depth_loss_type = l1

    #loss weight group 
    normal_weight_s1 = 0
    depth_weight_s1 = 1.0
    pc_weight_s1 = 0
    mask_weight_s1 = 1.0
    eikonal_weight_s1 = 1.0
    sdf_weight_s1 = 0
    con_weight_s1 = 0

    normal_weight_s2 = 1.0
    depth_weight_s2 = 1.0
    pc_weight_s2 = 0
    mask_weight_s2 = 3.0
    eikonal_weight_s2 = 1.0
    sdf_weight_s2 = 0
    con_weight_s2 = 0

    normal_weight_s3 = 1.0
    depth_weight_s3 = 0.0
    pc_weight_s3 = 0
    mask_weight_s3 = 3.0
    eikonal_weight_s3 = 1.0
    sdf_weight_s3 = 0
    con_weight_s3 = 0
}

val {
    save_freq = 500000

    val_normal_freq = 5000
    val_normal_resolution_level = 1
    gradient_method = ad  

    val_mesh_freq = 1000
    val_mesh_res = 512
    report_freq = 5
    eval_metric_freq = 1000
    visual_pose_freq = 500
}

model {
    sdf_network {
        d_out = 1
        d_in = 3
        d_hidden = 64
        n_layers = 1
        skip_in = [-1]  # -1 for no skip connection
        bias = 0.6
        geometric_init = True
        weight_norm = True
        input_concat = True  # concat input positions and encoded features
    }

    variance_network {
        init_val = 0.5
    }

    ray_marching {
        start_step_size = 1e-2
        end_step_size = 1e-3
        occ_threshold = 0.1
        occ_sigmoid_k = 80.0
        occ_resolution = 128
        occ_update_freq = 8  # batches
    }

    encoding{
        otype=HashGrid,
		n_levels=14
		n_features_per_level=2
		log2_hashmap_size=19
		base_resolution=32
		per_level_scale=1.3195079107728942
   }
   LearnScale{
    existscalenet = True
    learn_scale=True
    fix_scaleN = True
    scale_N = 1e0
   }

   LearnPose{
    learn_pose = True 
    learn_R=False
    learn_t=False
    init_pose=True
   }
}
