general {
    dataset_class = models.dataset_loader.Dataset
    renderer_class = models.renderer.NeuSRenderer

    base_exp_dir = ./exp/diligent_mv/CASE_NAME_minimal
    recording = [
        ./,
        ./models
    ]
    pose_init_radius = 15
    pose_init_angle = 25
    clock_wise = False
}

dataset {
    data_dir = ./data/diligent_mv_normals/CASE_NAME
    normal_dir = normal_camera_space_GT
    cameras_name = cameras_sphere.npz
    exclude_views = [5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]  # Use only first 5 views to reduce memory
    upsample_factor = 1
    depth_dir = integration/depth
    perspective_dir = integration/perspective
    add_pose_noise = False
    rotation_noise_std=0.1
    translation_noise_std=0.5
    depth_init_scale = 14.6
}

train {
    change_posenet_epoch = 99999  # Don't change pose network
    add_normal_loss_epoch = 0  # Add normal loss from start
    
    learning_rate = 1e-3  # Higher LR for faster convergence
    learning_rate_alpha = 0.05
    pose_lr = 0  # Don't learn pose to save memory
    scale_lr = 0  # Don't learn scale to save memory
    end_iter = 50  # Very short smoke test
    increase_bindwidth_every = 1000
    warm_up_end = 10
    gradient_method = ad  
    batch_size = 64  # Very small batch
    patch_size = 1
    use_white_bkgd = False
    pc_ratio = 4

    loss_type = l2
    depth_loss_type = l1

    # Simplified losses
    normal_weight_s1 = 0.5
    depth_weight_s1 = 0.1
    pc_weight_s1 = 0
    mask_weight_s1 = 1.0
    eikonal_weight_s1 = 0.1
    sdf_weight_s1 = 0
    con_weight_s1 = 0

    normal_weight_s2 = 0.5
    depth_weight_s2 = 0.1
    pc_weight_s2 = 0
    mask_weight_s2 = 1.0
    eikonal_weight_s2 = 0.1
    sdf_weight_s2 = 0
    con_weight_s2 = 0

    normal_weight_s3 = 0.5
    depth_weight_s3 = 0.0
    pc_weight_s3 = 0
    mask_weight_s3 = 1.0
    eikonal_weight_s3 = 0.1
    sdf_weight_s3 = 0
    con_weight_s3 = 0
}

val {
    save_freq = 50

    val_normal_freq = 1000
    val_normal_resolution_level = 4
    gradient_method = ad  

    val_mesh_freq = 50
    val_mesh_res = 64  # Very low res mesh
    report_freq = 10
    eval_metric_freq = 1000
    visual_pose_freq = 1000
}

model {
    sdf_network {
        d_out = 1
        d_in = 3
        d_hidden = 32  # Small network
        n_layers = 2  # Shallow network
        skip_in = [-1]  # No skip connections
        bias = 0.6
        geometric_init = True
        weight_norm = False  # Disable to save memory
        input_concat = False
    }

    variance_network {
        init_val = 0.5
    }

    ray_marching {
        start_step_size = 2e-2  # Larger steps
        end_step_size = 1e-3
        occ_threshold = 0.1
        occ_sigmoid_k = 80.0
        occ_resolution = 32  # Very small occupancy grid
        occ_update_freq = 16
    }

    # NO encoding section - will use plain MLP without tiny-cuda-nn
    
    LearnScale {
        existscalenet = True  # Enable but with lr=0
        learn_scale = False
        fix_scaleN = True
        scale_N = 1e0
    }

    LearnPose {
        learn_pose = True  # Enable but with lr=0 to avoid None issues
        learn_R = False
        learn_t = False
        init_pose = True
    }
}
